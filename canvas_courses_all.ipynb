{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from pandas.io import gbq\n",
    "#from google.cloud import bigquery,storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import gspread\n",
    "import json, os\n",
    "from canvasapi import Canvas\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from time import time\n",
    "\n",
    "from params import basedir, run_mode\n",
    "#import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev\n"
     ]
    }
   ],
   "source": [
    "#choose credential file paths and other possible changes:\n",
    "#run_mode = 'dev' #or, 'prod', or 'mig' for when migrating the code\n",
    "print(run_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_mode == 'dev':\n",
    "    out_table = \"all_courses3\"\n",
    "    tab_out_table = \"all_course_tabs3\"\n",
    "    \n",
    "elif run_mode == 'prod':\n",
    "    out_table = \"all_courses4\"\n",
    "    tab_out_table = \"all_course_tabs4\"    \n",
    "\n",
    "elif run_mode == 'prod_home':\n",
    "    out_table = \"all_courses4\"\n",
    "    tab_out_table = \"all_course_tabs4\"    \n",
    "\n",
    "    \n",
    "elif run_mode == 'mig':\n",
    "    out_table = \"all_courses3\"\n",
    "    tab_out_table = \"all_course_tabs3\"    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get Google cloud credentials\n",
    "project_id = 'canvas-portal-data-custom'\n",
    "cred_file = '{}/canvas-portal-data-custom-6e244db3b826.json'.format(basedir)\n",
    "data_dl = 'data'\n",
    "scopes = [ \"https://www.googleapis.com/auth/drive\", \"https://www.googleapis.com/auth/drive.file\",\n",
    "            \"https://spreadsheets.google.com/auth/spreadsheets\"]\n",
    "credentials = service_account.Credentials.from_service_account_file(cred_file,)\n",
    "\n",
    "#get Canvas credentials\n",
    "#cred_file2 = '{}/instances.json'.format(basedir)\n",
    "#with open(cred_file2,'r') as cred2:\n",
    "#    cred_json = json.load(cred2)\n",
    "\n",
    "from instances import canvas_api, panopto_api\n",
    "\n",
    "canvas_API_KEY = canvas_api['ACCES_TOKEN']\n",
    "canvas_API_URL = canvas_api['API_URL']#+'/accounts/1'\n",
    "\n",
    "panopto_client_id = panopto_api['Client Id']\n",
    "panopto_client_secret = panopto_api['Client Secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_Canvas__requester': <canvasapi.requester.Requester at 0x7f8d8b1b7b50>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a new Canvas object\n",
    "canvas = Canvas(canvas_API_URL, canvas_API_KEY)\n",
    "canvas.__dict__\n",
    "\n",
    "#Initialize a new Panopto object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get courses running on Canvas -- created via migration or by LT's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the LT list from the Excel sheet\n",
    "lt_df_new_cols = ['School', 'Dept_num', 'Dept_name', 'Name', 'Email']\n",
    "lt_existing_cols = ['School', 'Assigned to:', 'Department name', 'Name', 'Contact Email']\n",
    "lt_df = pd.read_excel('{}/Learning_Technologists_updating.xlsx'.format(basedir), engine=\"openpyxl\")\n",
    "lt_df = lt_df[lt_existing_cols]\n",
    "lt_df.columns = lt_df_new_cols\n",
    "lt_df['Email'] = lt_df.Email.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters etc. for course tab table\n",
    "#The tab information for each course will be obtained along with the course information\n",
    "#They will be appended in a list\n",
    "#The list will be turned to a dataframe and sent to GBQ\n",
    "tab_dict_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Read the Stellar to Canvas migration list on Google Drive, and construct a\\n#list of course_id s\\ngs_name = \"Stellar to Canvas content migration request (Responses)\"\\n#gs_name = \"xyz\"\\ngc = gspread.service_account(filename=cred_file)\\nsh = gc.open(gs_name).sheet1\\nsh_data = sh.get_all_values()\\nhead_col = sh_data.pop(0)\\nstellar_df = pd.DataFrame(sh_data, columns=head_col)\\nstellar_df[\\'course_id\\'] = stellar_df[\\'Canvas URL to migrate to\\'].str.split(\"/\").str[-1]\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Read the Stellar to Canvas migration list on Google Drive, and construct a\n",
    "#list of course_id s\n",
    "gs_name = \"Stellar to Canvas content migration request (Responses)\"\n",
    "#gs_name = \"xyz\"\n",
    "gc = gspread.service_account(filename=cred_file)\n",
    "sh = gc.open(gs_name).sheet1\n",
    "sh_data = sh.get_all_values()\n",
    "head_col = sh_data.pop(0)\n",
    "stellar_df = pd.DataFrame(sh_data, columns=head_col)\n",
    "stellar_df['course_id'] = stellar_df['Canvas URL to migrate to'].str.split(\"/\").str[-1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_info(course_id):\n",
    "    '''This function gets the course information and the file/assignment update times,\n",
    "    by the course_id, and returns a list of '''\n",
    "    cutoff_date = datetime.strptime('2015-05-31', '%Y-%m-%d') #by this time most default content was created\n",
    "    \n",
    "    try:\n",
    "        c1 = canvas.get_course(course_id, include='total_students')\n",
    "    except:\n",
    "        c1 = None\n",
    "        \n",
    "    try:\n",
    "        enrollment_term = term_dict[c1.enrollment_term_id]\n",
    "    except:\n",
    "        enrollment_term = None\n",
    "        \n",
    "    try:\n",
    "        course_dept = sub_account_dict[c1.account_id]\n",
    "    except:\n",
    "        course_dept = None\n",
    "\n",
    "        \n",
    "    try:\n",
    "        parent_account = parent_account_dict[c1.account_id]\n",
    "    except:\n",
    "        parent_account = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        course_name = c1.name\n",
    "        \n",
    "    except:\n",
    "        course_name = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        course_sis_id = c1.sis_course_id\n",
    "        \n",
    "    except:\n",
    "        course_sis_id = None        \n",
    "\n",
    "    try:\n",
    "        course_state = c1.workflow_state\n",
    "\n",
    "    except:\n",
    "        course_state = None\n",
    "\n",
    "        \n",
    "    try:\n",
    "        num_students = c1.total_students\n",
    "\n",
    "    except:\n",
    "        num_students = None\n",
    "        \n",
    "        \n",
    "    #Find out if the course is public or not:\n",
    "    try:    \n",
    "        is_public = c1.is_public\n",
    "    except:\n",
    "        is_public = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        public_syllabus = c1.public_syllabus\n",
    "    except:\n",
    "        public_syllabus = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        public_syllabus_to_auth = c1.public_syllabus_to_auth\n",
    "    except:\n",
    "        public_syllabus_to_auth = None\n",
    "\n",
    "\n",
    "    try:        \n",
    "        is_public_to_auth_users = c1.is_public_to_auth_users\n",
    "    except:\n",
    "        is_public_to_auth_users = None\n",
    "\n",
    "        \n",
    "        \n",
    "    if is_public == 1:\n",
    "        course_visibility = 'public'\n",
    "    elif is_public == 0 and is_public_to_auth_users == 1:\n",
    "        course_visibility = 'institute'\n",
    "    elif is_public == 0 and is_public_to_auth_users == 0:\n",
    "        course_visibility = 'not_public_to_auth_users'\n",
    "    else:\n",
    "        course_visibility = 'unknown'\n",
    "\n",
    "    #get discussion_topics, pages, quizzes, assignment_groups, modules, and module items\n",
    "    try:\n",
    "        list_dis_topics = c1.get_discussion_topics()\n",
    "    except:\n",
    "        list_dis_topics = []\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        list_pages = c1.get_pages()\n",
    "    except:\n",
    "        list_pages = []        \n",
    "        \n",
    "    try:\n",
    "        list_quizzes = c1.get_quizzes()\n",
    "    except:\n",
    "        list_quizzes = []        \n",
    "        \n",
    "    try:\n",
    "        list_assignment_groups = c1.get_assignment_groups()\n",
    "    except:\n",
    "        list_assignment_groups = []        \n",
    "\n",
    "    def count_stuff(list_items, if_published=None):\n",
    "        num_stuff = 0\n",
    "        for item in list_items:\n",
    "            if if_published != None:\n",
    "                if item.published == if_published:\n",
    "                    num_stuff += 1\n",
    "\n",
    "            elif if_published == None:\n",
    "                num_stuff += 1\n",
    "\n",
    "\n",
    "        return num_stuff\n",
    "\n",
    "    num_published_dis_topics = count_stuff(list_dis_topics, if_published=True)\n",
    "    num_published_pages = count_stuff(list_pages, if_published=True)\n",
    "    num_published_quizzes = count_stuff(list_quizzes, if_published=True)\n",
    "    num_assignment_groups = count_stuff(list_assignment_groups, if_published=None) \n",
    "    #Note: different if_published kwd\n",
    "\n",
    "    try:\n",
    "        modules_list = c1.get_modules()\n",
    "    except:\n",
    "        modules_list = []\n",
    "    num_modules = 0\n",
    "    num_module_items = 0\n",
    "\n",
    "    for d_ in modules_list:\n",
    "        num_modules += 1\n",
    "        num_module_items += d_.items_count\n",
    "\n",
    "\n",
    "    #get files and assignments\n",
    "    try:\n",
    "        files_ = c1.get_files()\n",
    "    except:\n",
    "        files_ = []\n",
    "        \n",
    "    try:\n",
    "        assn_ = c1.get_assignments()\n",
    "    except:\n",
    "        assn_ = []\n",
    "        \n",
    "    #Get the file updated times\n",
    "    file_utimes_all = [f_.updated_at for f_ in files_ ]        \n",
    "    file_utimes = [f_.updated_at for f_ in files_ if datetime.strptime(f_.updated_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]\n",
    "\n",
    "    #Get the file created times\n",
    "    file_ctimes_all = [f_.created_at for f_ in files_ ]\n",
    "    file_ctimes = [f_.created_at for f_ in files_ if datetime.strptime(f_.created_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]\n",
    "\n",
    "    #Get the assignment updated times\n",
    "    assn_utimes_all = [a_.updated_at for a_ in assn_ ]\n",
    "    assn_utimes = [a_.updated_at for a_ in assn_ if datetime.strptime(a_.updated_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]\n",
    "\n",
    "\n",
    "    #Get the assignment created times\n",
    "    assn_ctimes_all = [a_.created_at for a_ in assn_ ]\n",
    "    assn_ctimes = [a_.created_at for a_ in assn_ if datetime.strptime(a_.created_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]\n",
    "\n",
    "    \n",
    "    #Get the page updated times\n",
    "    page_utimes_all = [f_.updated_at for f_ in list_pages ]        \n",
    "    page_utimes = [f_.updated_at for f_ in list_pages if datetime.strptime(f_.updated_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]\n",
    "\n",
    "    #Get the page created times\n",
    "    page_ctimes_all = [f_.created_at for f_ in list_pages ]\n",
    "    page_ctimes = [f_.created_at for f_ in list_pages if datetime.strptime(f_.created_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]\n",
    "\n",
    "    #Get the quizzes lock_at times\n",
    "    #quizzes_utimes_all = [f_.lock_at for f_ in list_quizzes if f_.lock_at != None ]\n",
    "    #Get the quizzes due times\n",
    "    #quizzes_ctimes_all = [f_.due_at for f_ in list_quizzes if f_.due_at != None  ]\n",
    "    \n",
    "    quizzes_utimes = []\n",
    "    quizzes_ctimes = []\n",
    "    for f_ in list_quizzes:\n",
    "        try:\n",
    "            #if datetime.strptime(f_.lock_at, '%Y-%m-%dT%H:%M:%SZ') > cutoff_date:\n",
    "            if f_.lock_at != None:\n",
    "                quizzes_utimes.append(f_.lock_at)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if f_.due_at != None:\n",
    "                quizzes_ctimes.append(f_.due_at)\n",
    "        except:\n",
    "            pass                \n",
    "\n",
    "    \n",
    "    #Get the discussion topics last reply times\n",
    "    dtopics_utimes_all = [f_.last_reply_at for f_ in list_dis_topics if f_.last_reply_at != None ]        \n",
    "    dtopics_utimes = []\n",
    "    for f_ in list_dis_topics:\n",
    "        try:\n",
    "            if datetime.strptime(f_.last_reply_at, '%Y-%m-%dT%H:%M:%SZ') > cutoff_date:\n",
    "                dtopics_utimes.append(f_.last_reply_at)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    #Get the discussion topics created times\n",
    "    dtopics_ctimes_all = [f_.created_at for f_ in list_dis_topics ]\n",
    "    dtopics_ctimes = [f_.created_at for f_ in list_dis_topics if datetime.strptime(f_.created_at, \n",
    "                                                                    '%Y-%m-%dT%H:%M:%SZ') > cutoff_date]    \n",
    "    \n",
    "    \n",
    "    fa_times_all = file_utimes_all + assn_utimes_all + page_utimes_all + dtopics_utimes_all\n",
    "    fa_c_times_all = file_ctimes_all + assn_ctimes_all + page_ctimes_all + dtopics_ctimes_all\n",
    "\n",
    "    fa_times = file_utimes + assn_utimes + page_utimes + dtopics_utimes\n",
    "    fa_c_times = file_ctimes + assn_ctimes + page_ctimes + dtopics_ctimes\n",
    "\n",
    "\n",
    "    #Convert the whole thing \n",
    "    fa_times_all = np.array(fa_times_all, dtype='datetime64')\n",
    "    fa_c_times_all = np.array(fa_c_times_all, dtype='datetime64')\n",
    "\n",
    "    fa_times = np.array(fa_times, dtype='datetime64')\n",
    "    fa_c_times = np.array(fa_c_times, dtype='datetime64')      \n",
    "\n",
    "\n",
    "    try:\n",
    "        fa_max = fa_times.max() if len(fa_times)>0 else fa_times_all.max()\n",
    "    except:\n",
    "        fa_max = None\n",
    "        \n",
    "    try:\n",
    "        fa_c_min = fa_c_times.min() if len(fa_c_times)>0 else fa_c_times_all.min()\n",
    "    except:\n",
    "        fa_c_min = None\n",
    "\n",
    "    #find the farthest due/lock_at date for quizzes:\n",
    "    q_times = quizzes_utimes + quizzes_ctimes\n",
    "    q_times = np.array(q_times, dtype='datetime64')\n",
    "\n",
    "    try:\n",
    "        q_max = q_times.max() if len(q_times)>0 else None\n",
    "    except:\n",
    "        q_max = None\n",
    "        \n",
    "    try:    \n",
    "        #Get all tabs for this course\n",
    "        all_tabs = c1.get_tabs()\n",
    "\n",
    "        #Append the list of tabs to all_tabs_list\n",
    "        for tab_ in all_tabs:\n",
    "            tab_dict = tab_.__dict__\n",
    "            tab_dict['course_name'] = c1.name\n",
    "            \n",
    "            #print(tab_dict)\n",
    "            tab_dict_list.append(tab_dict)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "  \n",
    "    return [course_id, course_sis_id, course_dept, enrollment_term, parent_account, course_name, course_state,\n",
    "            len(file_utimes_all), len(assn_utimes_all), len(fa_times_all), \n",
    "            fa_max, fa_c_min, num_students, is_public, public_syllabus,\n",
    "           public_syllabus_to_auth, is_public_to_auth_users, course_visibility, num_published_dis_topics,\n",
    "            num_published_pages, num_published_quizzes, num_assignment_groups,num_modules, num_module_items, q_max]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of all department names by the sub-account id:\n",
    "acc = canvas.get_account(1)\n",
    "sub_account_dict = {}\n",
    "sub_account_dict[1] = 'MIT Root Account'\n",
    "parent_account_dict = {}\n",
    "accs = acc.get_subaccounts(recursive=True)\n",
    "for a_ in accs:\n",
    "    sub_account_dict[a_.id] = a_.name\n",
    "\n",
    "for a_ in accs:\n",
    "    try:\n",
    "        parent_account_dict[a_.id] = sub_account_dict[a_.parent_account_id]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    \n",
    "#Get course terms associated with the account and create a dictionary of the term names:\n",
    "term_dict ={}\n",
    "for term_ in acc.get_enrollment_terms():\n",
    "    term_dict[term_.id] = term_.name\n",
    "    \n",
    "#parent_account_dict\n",
    "#sub_account_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting a list of all courses...\n",
      "Getting a list of all courses... Done.\n"
     ]
    }
   ],
   "source": [
    "#Get a list of all courses:\n",
    "print(\"Getting a list of all courses...\")\n",
    "large_num = 100000 #give a very large number so all courses are pulled recursively\n",
    "#excl_acc = [1,17,76] #mention sub-accounts to be excluded\n",
    "excl_acc = [] #Don't implement it here...\n",
    "begin_date = '2015-05-01' #Date since when we are counting\n",
    "\n",
    "course_rows = []\n",
    "course_cols = ['course_id', 'course_code', 'course_name', 'account_id', 'created_at']\n",
    "for acc_course in acc.get_courses()[:large_num]:\n",
    "    course_rows.append([acc_course.id, acc_course.course_code, acc_course.name, acc_course.account_id, \n",
    "                        acc_course.created_at])\n",
    "    \n",
    "courses_df = pd.DataFrame.from_records(course_rows, columns=course_cols)\n",
    "\n",
    "courses_df_dep_excluded = courses_df[~courses_df.account_id.isin(excl_acc)]\n",
    "'''\n",
    "try:\n",
    "    courses_df_dep_excluded['Dept'] = courses_df_dep_excluded.apply(lambda \n",
    "                                                        row: sub_account_dict[row['account_id']], axis=1)\n",
    "except:\n",
    "    pass\n",
    "courses_df_dep_excluded\n",
    "'''\n",
    "filtered_courses_df = courses_df_dep_excluded[courses_df_dep_excluded.created_at>=begin_date]\n",
    "\n",
    "filtered_courses_df.to_csv('all_canvas_since_{}.csv'.format(begin_date), index=None)\n",
    "filtered_courses_df\n",
    "print(\"Getting a list of all courses... Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting course info for each course...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-70409fe6decc>:232: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_times_all = np.array(fa_times_all, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:233: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_c_times_all = np.array(fa_c_times_all, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:235: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_times = np.array(fa_times, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:236: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_c_times = np.array(fa_c_times, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:251: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  q_times = np.array(q_times, dtype='datetime64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 more courses done. Ending course_id 20\n",
      "(5, 27)\n",
      "Getting course info for each course... Done.\n"
     ]
    }
   ],
   "source": [
    "#Check that the migration/production/dev is set correctly\n",
    "print(\"Getting course info for each course...\")\n",
    "all_course_list_0 = filtered_courses_df.course_id.tolist()\n",
    "all_course_list_0_rows = []\n",
    "all_course_list_0_cols = ['course_id', 'course_sis_id', 'Dept', 'enrollment_term','parent_account', 'Course_name', \n",
    "    'course_state', 'num_files','num_assignments','num_tot_fa','last_update_at','first_created_at', 'num_students',\n",
    "            'is_public', 'public_syllabus', 'public_syllabus_to_auth', 'is_public_to_auth_users', 'course_visibility',\n",
    "            'num_published_dis_topics','num_published_pages', 'num_published_quizzes', 'num_assignment_groups',\n",
    "                          'num_modules', 'num_module_items','farthest_quiz_due_lock_date']\n",
    "\n",
    "if run_mode == 'dev' or run_mode=='mig':\n",
    "    num_courses = 5\n",
    "elif run_mode == 'prod' or run_mode=='prod_home':\n",
    "    num_courses = len(all_course_list_0) + 1\n",
    "    \n",
    "for c_id in all_course_list_0[:num_courses]:\n",
    "    all_course_list_0_rows.append(get_course_info(c_id))\n",
    "    #debug line\n",
    "    if len(all_course_list_0_rows)%5==0:\n",
    "        print(\"5 more courses done. Ending course_id {}\".format(c_id))\n",
    "    \n",
    "all_course_list_0_df = pd.DataFrame.from_records(all_course_list_0_rows, columns=all_course_list_0_cols)\n",
    "all_course_list_0_df['if_LT_led'] = 0\n",
    "all_course_list_0_df['LT_email'] = np.nan\n",
    "print(all_course_list_0_df.shape)\n",
    "all_course_list_0_df.tail()\n",
    "print(\"Getting course info for each course... Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-70409fe6decc>:232: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_times_all = np.array(fa_times_all, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:233: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_c_times_all = np.array(fa_c_times_all, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:235: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_times = np.array(fa_times, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:236: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  fa_c_times = np.array(fa_c_times, dtype='datetime64')\n",
      "<ipython-input-9-70409fe6decc>:251: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  q_times = np.array(q_times, dtype='datetime64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 27)\n"
     ]
    }
   ],
   "source": [
    "#Check that the migration/production/dev is set correctly\n",
    "lt_courses_row = []\n",
    "lt_courses_cols = all_course_list_0_cols + ['if_LT_led','LT_email']\n",
    "courses_to_exclude = [3157, 3158]\n",
    "lt_list = lt_df.Email.tolist()\n",
    "\n",
    "if run_mode == 'dev' or run_mode=='mig':\n",
    "    num_lts = 5\n",
    "elif run_mode == 'prod' or run_mode=='prod_home':\n",
    "    num_lts = len(lt_list) + 1\n",
    "\n",
    "\n",
    "for user_email in lt_list[:num_lts]:\n",
    "    try:\n",
    "        user_ = canvas.get_user(user_email, 'sis_login_id')\n",
    "        course_list = []\n",
    "        user_courses = user_.get_enrollments(type=['TeacherEnrollment'])\n",
    "\n",
    "        for uc_ in user_courses:\n",
    "            #print(uc_.id, uc_.course_id)\n",
    "            if uc_.course_id not in courses_to_exclude:\n",
    "                uc_row = get_course_info(uc_.course_id)\n",
    "                #print(uc_row)\n",
    "                uc_row.extend([1, user_email])\n",
    "                lt_courses_row.append(uc_row)\n",
    "    except Exception as e:\n",
    "        print('Error {} for user {}'.format(e, user_email))\n",
    "        pass\n",
    "\n",
    "\n",
    "all_lt_courses = pd.DataFrame.from_records(lt_courses_row, columns=lt_courses_cols)\n",
    "print(all_lt_courses.shape)\n",
    "#all_lt_courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_courses_df = pd.concat([all_course_list_0_df, all_lt_courses], ignore_index=True)\n",
    "#all_courses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anindyaroy/opt/anaconda3/envs/venv/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2224: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
      "  result, tz_parsed = tslib.array_to_datetime(\n"
     ]
    }
   ],
   "source": [
    "ts_cutoff_1w = pd.to_datetime('now') - pd.to_timedelta('7days')\n",
    "ts_cutoff_1m = pd.to_datetime('now') - pd.to_timedelta('30days')\n",
    "all_courses_df['if_active_last_week'] = np.where(all_courses_df.last_update_at>ts_cutoff_1w, True, False)\n",
    "all_courses_df['if_active_last_month'] = np.where(all_courses_df.last_update_at>ts_cutoff_1m, True, False)\n",
    "all_courses_df['if_active_since_June1'] = np.where(all_courses_df.first_created_at>=pd.to_datetime('2020-06-01'),\n",
    "                                                   True, False)\n",
    "all_courses_df['if_sandbox_course'] = np.where(all_courses_df.Dept=='Sandboxes', 1, 0)\n",
    "#all_courses_df['if_default_fa'] = np.where(all_courses_df.num_tot_fa==26, 1, 0)\n",
    "all_courses_df['if_default_fa'] = np.where(((all_courses_df.num_files==22) & \n",
    "                                            (all_courses_df.num_assignments==4)), 1, 0)\n",
    "\n",
    "all_courses_df = all_courses_df[all_courses_df.course_id.notna()].reset_index(drop=True)\n",
    "all_courses_df.drop_duplicates(subset=['course_id'], keep='last', inplace=True)\n",
    "#all_courses_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_courses_df['last_update_at'] = all_courses_df['last_update_at'].dt.strftime('%Y-%m-%d')\n",
    "all_courses_df['first_created_at'] = all_courses_df['first_created_at'].dt.strftime('%Y-%m-%d')\n",
    "all_courses_df['farthest_quiz_due_lock_date'] = all_courses_df['farthest_quiz_due_lock_date'].dt.strftime('%Y-%m-%d')\n",
    "#all_courses_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude the last day's information as that's still incomplete.\n",
    "all_courses_df['first_created_at'] = pd.to_datetime(all_courses_df['first_created_at'])\n",
    "all_courses_df = all_courses_df[all_courses_df.first_created_at!= all_courses_df['first_created_at'].max()]\n",
    "\n",
    "all_courses_df.to_gbq('lt_courses.{}'.format(out_table), project_id, if_exists='replace', credentials=credentials)\n",
    "#all_courses_df.to_csv('all_courses.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create course tab dataframe from the list:\n",
    "course_tab_df = pd.DataFrame(tab_dict_list)\n",
    "course_tab_df.drop(['_requester'], axis=1, inplace=True)\n",
    "#Send out course tabs dataframe to GBQ\n",
    "course_tab_df.to_gbq('lt_courses.{}'.format(tab_out_table), project_id, if_exists='replace', credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find total courses by date snapshot\n",
    "\n",
    "We'll take a snapshot of all the previous courses, and for each day, we'll add only the new numbers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
